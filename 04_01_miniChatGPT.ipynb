{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# miniGPT-v0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1801350, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>= Valkyria Chronicles III = \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senjō no Valkyria 3 : Unrecorded Chronicles (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The game began development in 2010 , carrying...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                                   \n",
       "1                     = Valkyria Chronicles III = \\n\n",
       "2                                                   \n",
       "3   Senjō no Valkyria 3 : Unrecorded Chronicles (...\n",
       "4   The game began development in 2010 , carrying..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1 = pd.read_parquet('./data/wikitext/train-00000-of-00002.parquet')\n",
    "train_2 = pd.read_parquet('./data/wikitext/train-00001-of-00002.parquet')\n",
    "train = pd.concat([train_1, train_2], axis=0)\n",
    "train.shape\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4358, 1), (3760, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_parquet('./data/wikitext/test-00000-of-00001.parquet')\n",
    "valid = pd.read_parquet('./data/wikitext/validation-00000-of-00001.parquet')\n",
    "test.shape , valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  = Valkyria Chronicles III = \\n   Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \\n  The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ' '.join(train['text'].astype(str)) \n",
    "data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\\x8f\\x92\\x93\\x94\\x96\\x9d¡¢£¤¥§©«\\xad®¯°±²³´µ¶·¹º»¼½¾¿ÀÁÂÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿĀāĂăąĆćĉĊċČčĎďĐđĒēĔĕĖėęĚěğĠġĢģĤĦħĩĪīĭįİıĵĶķĸĺļĽľŁłńņňŊŋŌōŏőŒœŖŗŘřŚśŜŞşŠšŢţťŧũŪūŭůűųŵŷŹźŻżŽžſƀƆƇƈƉƍƎƏƐƒƔƙƛơƢƥƭưƲƿǀǁǂǃǎǐǑǒǔǚǜǝǢǣǦǧǪǫǭǰǵǷǸǹǽȘșȚțȜȝȟȯȳȷȼɈɐɑɒɓɔɕɖɗɘəɚɛɜɞɟɠɡɢɣɤɥɦɧɨɪɫɬɭɮɯɰɱɲɳɴɵɶɷɸɹɺɻɽɾʀʁʂʃʄʇʈʉʊʋʌʍʎʏʐʑʒʔʕʖʗʘʙʛʝʟʠʡʢʰʱʲʳʷʹʻʼʽʾʿˀˁˆˇˈˌːˑ˔˕˖˘˚˜˞ˠˢˣˤ˥˦˧˨˩̧̖̗̝̞̟̠̣̤̥̩̪̬̮̯̰̱̲̳̺͍̀́̂̃̄̆̇̈̊̋̌̍̏̐̑̽͌̚͘͜͡΄ΆΈΉΊΌΎΐΑΒΓΔΕΖΗΘΙΚΛΜΝΞΟΠΡΣΤΥΦΧΨΩάέήίαβγδεζηθικλμνξοπρςστυφχψωϊόύώϑϕϝϟϵЂЄІЇЈЉЋАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяёђєіїјљњћѝўѠѡѢѣѥѧѮѹ҆ғқүҳҷӣӨөӯӶӷԱԲԳԴԵԶԷԸԹԺԻԼԽԿՀՁՂՃՄՅՆՇՈՊՋՌՍՎՏՓՔՕաբգդեզէըթժիլխծկհձղճմյնշոչպջռսվտրցւփքօևְֱֲֳִֵֶַָֹֻּֽֿׁׂ֤֫אבגדהוזחטיךכלםמןנסעףפץצקרשתױ׳،ءآأؤإئابةتثجحخدذرزسشصضطظعغـفقكلمنهوىئًٌٍَُِّْ١٧ٰپچڈڠکڬگںھہیۍےەܐܒܔܕܗܘܙܚܛܝܠܡܢܣܥܦܪܬܼ݂ܲܵँंःअआइईउऋएऐऔकखगघङचछजञटठडणतथदधनपफबभमयरलवशषसह़ऽािीुूृॆेैॉॊोौ्ॐ।॥१२३ংঅআইএকখগঙচজটডঢণতথদনপবভমযরলশষসহ়ািীুূেৈো্ৰਂਅਉਖਘਜਝਦਲਵਸਹ਼ਾਿੁੇੰੱખફબરલસાોପରୀୁஃஅஆஇஈஎஒகஙசடணதநனபமயரறலளழவஸாிீுூெேைோ்ంకఖగజటఠడతథదనపబభమయరలవషసాిీుైో్ಂಃಕಖಗಚಟಠಡತದನಪಬಭಮಯರಱಲಳವಶಸಹಾಿುೇೋ್ೞഅങദനപമയരളവശസഹാി്අඑකගජතධනපමයරලවශහළ්ාැිුේෝกขคฆงจฉชซญฎฏฐฑณดตถทธนบปผฝพฟภมยรฤลวศษสหฬอฮะัาำิีึืุู฿เแโใไ็่้๊์་༌།ཀཁགངཆཇཐདནཔབམཙཚཛའཡརལསཧིེོུྟྡྣྤྥྱྲကဂငစဆနပဗဘမယရလဝဟာိီုူဲး္်ျြှႠႢႣႨႬႵႿაბგდევზთიკლმნოპჟრსტუფქღყშჩცძწჭხჯჰჱჲჳჴჵჶჷჸჹჺ჻ሀለሐሓሕመማሥረርሰስቆቈበብቲታትነናንኖአኢእከኲዕዘዛየያይዮደድጅገጉጵፈፍ፡ᎠᎣᎦᎨᎩᎰᎳᎹᏍᏯᏱᐊᑲᒡᓘᚢᚣᚦᚨᚩᚬᚱᚷᚹᚺᚻᚼᚾᛁᛃᛄᛇᛋᛏᛒᛗᛚᛝᛞᛟᛠកខគងចឆជញដឋណតថទធនបពភមយរលវសហអឥឪឫឯ឵ាិីឹឺុូួៀេែៃោៅំះៈ៉់្ᠠᠣᠨᠪᠮᠯᠰᠴᠵᠸᡝᡠᡥᡨᡳᡴᡵᴰᴷᴺᵀᵊᵑᵗᵘᵝᵻᵿᶑᶢᶦᶴᶷ᷽᷄᷅᷆᷇᷈᷉ḌḍḎḏḑḕḗḢḤḥḨḩḪḫḭḱḲḳḵḷḹḻḿṁṃṅṇṉṓṙṚṛṜṝṟṢṣṦṪṬṭṮṯṳṵṼṽẃẒẓẖạảẤấầẨẩẫậắằẵặẹẻẽếềểễệỉịỌọỏỐốồổỗộớờởợỤụủỨứừửữựỳỵỹἀἁἂἃἄἅἈἉἌἍἐἑἒἔἕἘἙἜἝἠἡἢἤἥἦἧἨἩἰἱἲἳἴἵἶἷἸἹἾὀὁὂὃὄὅὉὌὐὑὔὕὖὗὝὡὣὤὥὦὨὩὮὰὲὴὶὸὺὼᾓᾰᾳᾶᾷ᾿ῆῇῈῐῑῖῚῠῥῦῬῳῶῷ\\u200b\\u200c\\u200d‐‑‒–—―‖‘’‚‛“”„‟†‡•…‰′″※‼‿⁄⁊\\u2060\\u2061⁰⁺ⁿ₁₂₃₄₡₣₤₦₧₨₩₫€₱₴₹ℂ℃ℓℕ№ℛℝ℞™ℤ℥ℵ⅓⅔⅙⅛⅜⅝⅞Ⅱ←↑→↓↔↗↘↦↪↵⇄⇌⇒⇪∀∂∅∆∇∈∉∊∑−∕∖∗∘√∝∞∤∩∪∫∴∼≈≠≡≢≤≥≪≫≲⊂⊕⊗⊙⊞⊢⊣⊥⋅⋆⋯⌊⌋⌘①②③④⑤⑥⑦⑧─█▢▲▼○●◦☄★☆☉☧☫☭☽☾♀♂♄♅♆♇♈♉♠♣♥♦♩♪♭♮♯⚳⚴⚵⛢✡✱❄❅❆❤⟦⟧⟨⟩⥇⩽⫶ⱱⲁⲛⲥⲧⲩⲪⲱⴰⴳⴷⴻⴼⴽⵃⵇⵉⵍⵎⵏⵓⵔⵕⵖⵙⵛⵜⵡⵢⵣ⸨⸩、。々〈〉《》「」『』【】〒〜あぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞただちっつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもゃやゅゆょよらりるれろわゑをんァアィイゥウェエォオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモャヤュユョヨラリルレロワヲンヴヶ・ー一丁七万丈三上下不与丑且世丘丙东丝丞両丨个中丶丸丹为主丽丿乃久么义之乌乎乐乘乙乚乛九也习书乩买乱乳乾亀亅了予争事二云五井亚些亜亞亡交亦亨京亮亰人什仁仇今介仔仕他付仙代令以仪们仮仰仲件任份伊伏伐休会伝伟传伪伯伴伸似佃但位住佐佑体何余佛作你佳併使來例侍侗供依侠侨侬侯係促俄俊保信俭修俱俳倉個們候借倪倫倭偃假偏健側偵偽傀傅傑傘備催傭傳傷像僑僕僧儀億儒儚儡優儿允元充兆先光克免兒兔兜入內全兩八公六兰共关兵其具典养冀内円冉册再冒写军冠冥冫冬冯决冴冶冷净准凌凤処凪凯凰凱凶凹出刀刃分切刊划列刘初判別利别到制刷券刹刺刻則前剑剛剣剧剩副割創劃劇劉劍力办功加劣动助劳勃勅勇勒動勘務勝勞勢勳勾包化北匠匹区医區十千升午半华协卐卒卓協单卖南博卜占卡卢卦卫印危即却卸卿厂厄历厘厚原厥厦厩去县参參叉及友双反収发叔取受变叛叠叡叢口古句只叫召可台史右叶号司合吉同名后向吕君吞吟吧启吳吴吸吹吾呂呉告周呪味呼命咆和咖咙咫咲咸哀品哈哉响員哥哮哲唄唐唯唱商問啓啟啡善喇喋喚喜喝喬嘉嘘噛器嚣嚴囁囂囃囚四回因团団図国图圈國圍圏園圓圖土圣圧在地圻坂均坊坑块坚坝坡坤坪型垣城埔域執培基堀堂堅堆堡堤堯報場塊塔塘塚塞塩填塵境墓墙增壁壌壓壟壤士壬壮壯声壱売壳壷壽处备変复夏夕外多夜够夢夤大天太夫央失头夷奇奈奉奎奏奐契奔奥奧奪女奴好如妃妇妍妖妙妮妹妻姉姊始姑委姚姥姦姫姬姿威娘娜婁婆婚婷嫁嬢嬴子孔字存孙孛孝孟季孤学孩孫孵學宁宅宇守安宋完宏宗官宙定宜宝实実客宣室宫宮宴宵家宸容宿寂寄密寇富寔寗寛寝寞察寧寨審寬寵寶寸对寺寻対寿封射将將尉尊尋對導小少尔尚尧就尸尹尺尼尽尾局居届屋屍屑展屠層屬屯山屿岐岑岚岛岡岩岬岭岳岸峰島崇崎崔崖嵐嶋嶺嶼巂巖川州巡工左巨巫差己巳巴巻币市布帆师希帕帖帝帥带師帮帰帶常幕幡幣干平年幸幻幽广庁広庄庆庇序库底庖店庙庚府度座庫庭庵康廉廊廖廟廣廬延廷建廻廿开弁式弐弓弔引弘弟张弥弦弧弱張強弹强弾彌当录彖彙形彦彩彪彬彭影役彼征径待律後徐徒得從御復微徳德徹徽心必忍志忘応忠快念怀怎怒怖思怡急性怨怪总恆恋恐恒恢恥恩恭息恵恼悔悟悠悦悪悫悲悼情惑惟惠惡想愁愍意愚愛感愽慈態慎慧慰慶憂憎憑憲憶應懍懷戈戊戎成我战戦戯戰戴户戸房所扁扇扈扉手才打托扶找承技抄抓投抜択护报披抱抵担拉拍拏拐拖拘招拜拟拥括拳拾持挂指挑挥振据捷授掛採探控掲描提揚換援揺摂摩摸撃撒撞播撲操攝支收改攻放政故敏救教敢散敦敬数敵敷數文斉斎斗料斜斤斩斬断斯新方於施旅旋族旗无日旦旧早旭时旺昂昇昌明昏易昔星映春昭是昼時晉晋晒普景晴晶智暁暂暖暗暦暮暴曆曜曦曲更書曹曼曾最會月有朋服朏朔朗望朝期朧木未末本札朱朴朵机朽杀杂权李杏材村杖杜束条来杨杯東杲松板极析林枚果枝枭枯架柆柏柔柚柩柱柳柴査栄标栈树栖栗栞校株样核根格栽栾桀桂桃案桎桐桑桓桜桥桧梁梅梏梓條梦梨梭梯械梵梶棋棍棗棘棚棟森棲棵棺椅植椎椒椛検椰椿楊楚楠業楯極楼楽概榆榊榔榛榮榴槐様槤槻樂樉樊樓樗標樛模権横樱樸樹橋橘橚機橫橿檀檜檳檻櫓櫻權欒欠次欣欲欽歌歓歡止正步武歩歪歲歳歴歷歸死殊残段殺殻殿毅母毎每比毕毘毛毫毬氏民气気氣水氷永氾汇汉汐汗汝江池汤汪汰汶決汽沂沃沈沉沌沐沒沖沙沛没沢沫河沸油治沼沽泉泊法泗泡波泣泥注泰泾洁洋洛洞津洪洲活派流浅浙浚浜浦浩浪浮海消涙润涵涼淇淑淘淡淨深淳淵淹添清渊渚減渠渡渣渥渦温測港游渾湊湖湯湾満源準溜溢溪溫溶滅滋滑滨滿漁漂漆漏漠漢漫漳漸潘潜潤澄澤澪激濃濞濟瀛瀬灣火灯灰灵灶灼災灾炎炬炮炯炷炸点為炼烈烏烙烟烦烧焉焔無焦然焼煌煙煜照煩煮熊熔熙熟熱燃燈燕營爆爪爭爱爲爵父爺爻爽爾片版牌牙牛牡牢牧物牵特犖犬犯狀狂狐狗狛狡狩独狭狱狸狼猛猩猪猫献猿獄獅獣獵獻玄玉王玖玩玲珂珍珙珠現球理琦琪琬琮琴瑋瑙瑜瑞瑠瑣瑪瑾璉環璽瓊瓜瓢瓦瓩瓷甘甜生產産用甫田由甲申男町画甽界畑留畜畢略番畫異疾病症痘痛痴瘡瘤発登發白百的皇皙皮皿盆盈益盏盐监盒盗盘盛盟監盤盧目直相盼省看県眞真眼着督瞬瞳矢知矩短矮矯石砂砍研砖砲破硕硝硨碍碗碩確碼磁磅磐磨磯磲礁礎礮示礼社祀祈祐祖祚神祠祥票祭祺祿禁禄禎福禦禮禰禺禾秀私秋科秒秘租秤秦移程稔稚種稲稷穂穌積穎穗穢究空突窓窗窟竇立站竜章童端竹竺笑笔笛笠符笨第笹筆等筋筍筐筑答策筹箇算管箪箭箱節範篇篋篚篤簡簿籃籌籍籠米籵粁粉粍粟粥粨精糊糎糖糸系紀約紅紋納純紘紙級素紡紫細紹紺終組絆経結絡給統絵絶綁經継続綜綠維綯綱網綸綺綾緋総緑緒線締編緩緯縄縊縣總繋織繼續红级纪纯纲纵线组绅细终绍经给统继绮维综缽网罗罠罪置罰罸羅羊美群義羽翁習翔翘翠翡翱翹翻翼老考者耆而耕耳耶耿聃联聖聘聚聞聡聯聰聲職肃肉肖肚股肥肩育胞胠胡胤胴胸能脂脇脈脉脚脩脱脳腎腐腰腹腿膀膺臂臘臚臣臨自臭至致臺與興舍舎舞舟航船艦良色艳艶艺节芒芙芝芦芬芭芮芯花芳芸芹芽苏苑苗苣若英苺茂范茅茜茶茸草荊荒荔荘荥荪荫药荷荻荼莉莊莎莘莞莫莱莲莴菇菉菊菜華菱菲萌萍萝营萧萨萬落葆葉著葛董葦葫葵蒙蒭蒲蒼蒿蓀蓑蓝蓮蔡蔭蔵蕃蕉蕨蕩蕭薇薊薔薙薛薩薫薯藍藏藕藝藤藥藩藻蘄蘅蘇蘑蘭虎虐虔處虚虛號虫虹蛇蛍蛙蛭蜃蜡蝉蝕蝶融螺蟲蠕蠻血衆行術街衙衛衝衡衢衣补表袁袈袖被裁裂装裏裔裕補裟裳裸製褒襄襟襲西要覇見規視覚親観覺觀观角解触觳言計記設許訳証詔詞詠試詩話誌誐誒誓誕誘語誠誡誦說説読誰課調談論諭諷諸謀謁謎謙講謝謡識譚譜警議護讀變讐讓计让议许论讼诉词诗诚话语诶请诺读课谁谦谭谷豆豊豌豐豚象豪豫豬豹貓貝貞負財貫貴費賀資賈賊賓賞賢賦質購贝贞财贤质贵贺贼资赤赭走赵起超越趙足跆跑跖跟跡路跳踊踏踢蹴身車軌軍軒転軽載輔輛輝輪輿轉车轩转辆辉辛辣辭辯辰農边辺辽达辿迄迅过迈运近返这进远迦迪述迷追送适逆选這通造逢連逯週進遁遇遊運遍過道達遗遙遜遠遥遮選遺遼避邁還邊邑邓那邦邪邱郁郊郎郑郛郝郡部郭郷都鄧鄭酈酉酒酔酥酱酷酸醋醒醫采釈釋里重野量金釗釣鈍鈴鉄鉢鉦鉱鉴銀銃銅銓銖銘銳鋒鋪鋼錄錡錦錬録鍋鍵鎖鎧鎮鏡鐘鐵鐸鑒钊钢钦钱铁铎铜铭铺锡键镇镗镜長长門閃開閏閒間関閣閨闇闍闕闘關门问闯阁阪防阳阿陀附际陈降限陛院陣除陪陳陵陶陸険陽隆隊階隔隗隠隣隱隴隸隻隼雀雁雄雅集雇雉雎雕雙雛雜雞離難雨雪雲雳零雷電雾需霆震霊霍霖霜霞霧霰露霸霹靂靈青靖静非靠面革靴靼鞋鞍鞠韃韋韓韦韩韭音韶響頃項順須頌領頭顆題額顏顔願顯项顾颂颊颖颗颜風颪颱飄风飛飞食飯飾餅養餓館饼馆馒首香馬馮駆駐駒駙駢駿騎騒験騭騰騷驁驚驤马驰骨骸髀高髪鬘鬥鬪鬼魂魄魔魚魯鮑鮫鮮鯖鯵鰐鱀鱼鲁鲤鳥鳩鳳鳴鳶鴉鴣鴨鴻鵡鵩鵬鶍鶴鷓鷹鷺鸚鸟鸡鸭鸿鹅鹹鹼鹽鹿麗麥麵麻麼麾黃黄黎黑黒黙黛黨鼉鼎鼓鼠鼻齉齊齋齐龍龙ꜛꜜꜣꜩꜫꜭꞅꞎꞰꞵꦂꦠꦯꦲꦸꭓ가간강개거건경계고공관광구국권귀그극근글금급기김꺼껐나날남났내너네념노놔눈늬다단대더도독돌동디딱라람래런렌려렬로록론루류르를리립마막만말명목무문물미민믿바박방백뱅버범법별병보복봐부불붉빅빙빤뿐사산살삼삿상새색서성센소쇼수순술숫스시식신실쌤아안알암앙애앤야양어에엔연영예오온왜용운울원위유은을음의이인일자장재적전점정제조종좋주줄중지진집짓징차천청체쳐초춘충치커코킨타태터퇴투트특파판퍼평표풍피하학한합해행향허헬호혹홀화회후희ﬀﬁﬂﮭﮮﷲﷺ️︠︡ﺒﻉﻋﻔﻴ\\ufeff！％＆（），－／１２３４６：＜＝＞？ＡＣＤＧＩＪＬＭＰＲＸ［］｜～｢｣･ｰ￥�𐀁𐀈𐀫𐎠𐎢𐎭𐎰𐎹𐎺𐎼𐏁𐭃𐭉𐭓𐭕𒀯𒀳𝕄𝕡🖕',\n",
       " 4979)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(data) # 540,095,682 characters = 540 M \n",
    "unq_chars =  ''.join(sorted(set(data)))\n",
    "unq_chars , len(unq_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bout seven times through the music production due '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(unq_chars[:96])\n",
    "chars_count = 96 \n",
    "chars = unq_chars[:96]\n",
    "data[12000:12000 + 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539440918\n"
     ]
    }
   ],
   "source": [
    "pattern = f\"[{re.escape(chars)}\\s]\"\n",
    "data2 = ''.join(re.findall(pattern, data))\n",
    "print(len(data2)) # 539440918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "539440918"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'  = Valkyria Chronicles III = \\n   Senj no Valkyria 3 : Unrecorded Chronicles ( Japanese : 3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \\n  The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game \\'s opening theme was sung by May \\'n . \\n  It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game \\'s expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \\n   = = Gameplay = = \\n   As with previous Valkyira Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military un'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data2)\n",
    "data2[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534851193, 4589725)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_words(text):\n",
    "    text = re.sub(r'[ ]+', ' ', text)\n",
    "    text = re.sub(r'[\\n]+', '\\n', text)\n",
    "    text = re.sub(r'@.*?@', ' ', text)\n",
    "    text = re.sub(r'\\(\\s*\\)', ' ', text)\n",
    "    text = re.sub(r'\\[\\s*\\]', ' ', text)\n",
    "    text = re.sub(r'\\{\\s*\\}', ' ', text)\n",
    "    return text.strip()\n",
    "data3 = clean_words(data2)\n",
    "\n",
    "len(data3) , len(data2) - len(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532467393, 2383800)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4 = clean_words(data3)\n",
    "len(data4) , len(data3) - len(data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532467359, 34)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5 = clean_words(data4)\n",
    "len(data5) , len(data4) - len(data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532467359, 0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6 = clean_words(data5)\n",
    "len(data6) , len(data5) - len(data6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532467359"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = data6\n",
    "open('./data/wikitext/processed.txt', 'w').write(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PReprocess - extract articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading = r'\\s=.*=\\s'\n",
    "hs = re.findall(heading, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29525,\n",
       " [' = Valkyria Chronicles III = ',\n",
       "  ' = Tower Building of the Little Rock Arsenal = ',\n",
       "  ' = Cicely Mary Barker = ',\n",
       "  \" = Gambia women 's national football team = \",\n",
       "  ' = Plain maskray = ',\n",
       "  ' = 2011 – 12 Columbus Blue Jackets season = ',\n",
       "  ' = Position ; GP = ',\n",
       "  ' = Goals ; A = ',\n",
       "  ' = Points ; PIM = ',\n",
       "  ' = Games Played ; TOI = '])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headings = []\n",
    "for h in hs:\n",
    "    if re.findall(r'=',h).count('=') == 2:\n",
    "        headings.append(h)\n",
    "len(headings),headings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' = West Hendford Cricket Ground , Yeovil = ',\n",
       " \" = New Year 's Eve ( Up All Night ) = \",\n",
       " ' = World War Z = ',\n",
       " ' = Sentence spacing = ',\n",
       " ' = The Crab with the Golden Claws = ',\n",
       " ' = L.A.M.B. = ',\n",
       " ' = First @-@ move advantage in chess = ',\n",
       " ' = Frederick Reines = ',\n",
       " ' = Lock Haven , Pennsylvania = ',\n",
       " ' = Rachel Green = ',\n",
       " ' = Krak des Chevaliers = ',\n",
       " ' = The Importance of Being Earnest = ',\n",
       " ' = Lloyd Mathews = ',\n",
       " ' = HMS Boreas ( H77 ) = ',\n",
       " ' = Kaimanawa horse = ']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headings[100:100 + 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = Sentence spacing = \n",
      "   Sentence spacing is the horizontal space between sentences in typeset text . It is a matter of typographical convention . Since the introduction of movable @-@ type printing in Europe , various sentence spacing conventions have been used in languages with a Latin alphabet . These include a normal word space ( as between the words in a sentence ) , a single enlarged space , and two full spaces . \n",
      "  Until the 20th century , publishing houses and printers in many countries used additional space between sentences . There were exceptions to this traditional spacing method — some printers used spacing between sentences that was no wider than word spacing . This was French spacing — a term synonymous with single @-@ space sentence spacing until the late 20th century . With the introduction of the typewriter in the late 19th century , typists used two spaces between sentences to mimic the style used by traditional typesetters . While wide sentence spacing was phased out in the printing industry in the mid @-@ twentieth century , the practice continued on typewriters and later on computers . Perhaps because of this , many modern sources now incorrectly claim that wide spacing was created for the typewriter . \n",
      "  The desired or correct sentence spacing is often debated but many sources now say additional space is not necessary or desirable . From around 1950 , single sentence spacing became standard in books , magazines and newspapers and the majority of style guides that use a Latin @-@ derived alphabet as a language base now prescribe or recommend the use of a single space after the concluding punctuation of a sentence . However , some sources still state that additional spacing is correct or acceptable . The debate continues on the World Wide Web . Many people prefer double sentence spacing for informal use because that was how they were taught to type . There is a debate on which convention is more readable ; the few recent direct studies conducted since 2002 have produced inconclusive results . \n",
      "   = = History = = \n",
      "    = = = Traditional typesetting = = = \n",
      "   Shortly after the invention of movable type , highly variable spacing was created that could create spaces of any size , and allowed for perfectly even justification . Early American , English , and other European typesetters ' style guides ( also known as printers ' rules ) specified spacing standards that were all essentially identical from the 18th century onwards . These guides — e.g. , Jacobi in the UK ( 1890 ) and MacKellar , Harpel , and De Vinne ( 1866 – 1901 ) in the U.S. — indicated that sentences should be em @-@ spaced , and that words should be 1 / 3 or 1 / 2 em @-@ spaced ( illustration right ) . The relative size of the sentence spacing would vary depending on the size of the word spaces and the justification needs . For most countries , this remained the standard for published work until the 20th century . Yet , even in this period , there were publishing houses ( notably in France ) that used a standard word space between sentences — a technique called French spacing ( illustration below ) . \n",
      "   = = = Mechanical type and the advent of the typewriter = = = \n",
      "   Mechanical type systems introduced near the end of the 19th century , such as the Linotype and Monotype machines , allowed for some variable sentence spacing similar to hand composition . Just as these machines revolutionized the mass production of text , the advent of the typewriter around the same time revolutionized the creation of personal and business documents . But the typewriters ' mechanical limitations did not allow variable spacing — typists could only choose the number of times they pressed the space bar . Typists in some English @-@ speaking countries initially learned to insert three spaces between sentences to approximate the wider sentence spacing used in traditional printing , but later settled on two spaces , a practice that continued throughout the 20th century . This became known as English spacing , and marked a divergence from French typists , who continued to use French spacing . \n",
      "   = = = Transition to single spacing = = = \n",
      "   In the early 20th century , some printers began using one and a half interword spaces ( an \" en quad \" ) to separate sentences . This standard continued in use , to some extent , into the 1990s . \n",
      "  Magazines , newspapers , and books began to adopt the single space convention in the United States in the 1940s and in the United Kingdom in the 1950s . Typists did not move to single spacing simultaneously . The average writer still relied on the typewriter to create text — with its inherent mechanical spacing limitations . \n",
      "  Technological advances began affecting sentence spacing methods . In 1941 , IBM introduced the Executive , a typewriter capable of proportional spacing — which had been used in professional typesetting for hundreds of years . This innovation broke the hold that the monospaced font had on the typewriter — reducing the severity of its mechanical limitations . By the 1960s , electronic phototypesetting systems ignored runs of white space in text . This was also true of the World Wide Web , as HTML normally ignores additional spacing , although in 2011 the CSS 2 @.@ 1 standard officially added an option that can preserve additional spaces . In the 1980s , desktop publishing software provided the average writer with more advanced formatting tools . By the late 20th century , literature on the written word had begun to adjust its guidance on sentence spacing . \n",
      "   = = Modern literature = = \n",
      "    = = = Typography = = = \n",
      "   Early positions on typography ( the \" arrangement and appearance of text \" ) supported traditional spacing techniques in English publications . In 1954 , Geoffrey Dowding 's book , Finer Points in the Spacing and Arrangement of Type , underscored the widespread shift from a single enlarged em space to a standard word space between sentences . \n",
      "  With the advent of the computer age , typographers began deprecating double spacing , even in monospaced text . In 1989 , Desktop Publishing by Design stated that \" typesetting requires only one space after periods , question marks , exclamation points , and colons \" , and identified single sentence spacing as a typographic convention . Stop Stealing Sheep & Find Out How Type Works ( 1993 ) and Designing with Type : The Essential Guide to Typography ( 2006 ) both indicate that uniform spacing should be used between words , including between sentences . \n",
      "  More recent works on typography weigh in strongly . Ilene Strizver , founder of the Type Studio , says , \" Forget about tolerating differences of opinion : typographically speaking , typing two spaces before the start of a new sentence is absolutely , unequivocally wrong . \" The Complete Manual on Typography ( 2003 ) states that \" The typewriter tradition of separating sentences with two word spaces after a period has no place in typesetting \" and the single space is \" standard typographic practice \" . The Elements of Typographic Style ( 2004 ) advocates a single space between sentences , noting that \" your typing as well as your typesetting will benefit from unlearning this quaint [ double spacing ] Victorian habit . \" \n",
      "  David Jury 's book , About Face : Reviving the Rules of Typography ( 2004 ) — published in Switzerland — clarifies the contemporary typographic position on sentence spacing : \n",
      "  Word spaces , preceding or following punctuation , should be optically adjusted to appear to be of the same value as a standard word space . If a standard word space is inserted after a full point or a comma , then , optically , this produces a space of up to 50 % wider than that of other word spaces within a line of type . This is because these punctuation marks carry space above them , which , when added to the adjacent standard word spaces , combines to create a visually larger space . Some argue that the \" additional \" space after a comma and full point serves as a \" pause signal \" for the reader . But this is unnecessary ( and visually disruptive ) since the pause signal is provided by the punctuation mark itself . \n",
      "   = = = Style and language guides = = = \n",
      "    = = = = Style guides = = = = \n",
      "   Early style guides for typesetting used a wider space between sentences than between words – \" traditional spacing \" , as shown in the illustration to the right . During the 20th century , style guides commonly mandated two spaces between sentences for typewritten manuscripts , which were used prior to professionally typesetting the work . As computer desktop publishing became commonplace , typewritten manuscripts became less relevant and most style guides stopped making distinctions between manuscripts and final typeset products . In the same period , style guides began changing their guidance on sentence spacing . The 1969 edition of the Chicago Manual of Style used em spaces between sentences in its text ; by the 2003 edition it had changed to single sentence spacing for both manuscript and print . By the 1980s , the United Kingdom 's Hart 's Rules ( 1983 ) had shifted to single sentence spacing . Other style guides followed suit in the 1990s . Soon after the beginning of the 21st century , the majority of style guides had changed to indicate that only one word space was proper between sentences . \n",
      "  Modern style guides provide standards and guidance for the written language . These works are important to writers since \" virtually all professional editors work closely with one of them in editing a manuscript for publication . \" Late editions of comprehensive style guides , such as the Oxford Style Manual ( 2003 ) in the United Kingdom and the Chicago Manual of Style ( 2010 ) in the United States , provide standards for a wide variety of writing and design topics , including sentence spacing . The majority of style guides now prescribe the use of a single space after terminal punctuation in final written wo\n"
     ]
    }
   ],
   "source": [
    "for i in re.finditer(headings[100 + 3], data):\n",
    "    idx = i.start()\n",
    "    print(data[idx : idx + 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[34], line 7\u001b[0m\n",
      "\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m re\u001b[38;5;241m.\u001b[39mfinditer(headings[h], data):\n",
      "\u001b[0;32m      6\u001b[0m         heading_idx[h] \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39mstart()\n",
      "\u001b[1;32m----> 7\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;32m      9\u001b[0m     heading_idx[h] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "heading_idx = {}\n",
    "for h in range(len(headings)):\n",
    "    try:\n",
    "        for i in re.finditer(headings[h], data):\n",
    "            heading_idx[h] = i.start()\n",
    "            break\n",
    "    except:\n",
    "        heading_idx[h] = None\n",
    "len(heading_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(headings)):\n",
    "    if i == len(headings) - 1:\n",
    "        articles.append(data[heading_idx[i]:])\n",
    "    else:\n",
    "        articles.append(data[heading_idx[i]:heading_idx[i+1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_lens = np.array([len(a) for a in articles])\n",
    "print(f'Data len : {len(data)}\\nArticles len: {article_lens.sum()} , {article_lens.mean()}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532467359\n"
     ]
    }
   ],
   "source": [
    "data = open('./data/wikitext/processed.txt', 'r').read()\n",
    "print(len(data)) # 532,467,359 characters = 532 M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 104392756),\n",
       " ('e', 49091225),\n",
       " ('t', 34095601),\n",
       " ('a', 33724387),\n",
       " ('n', 29289422),\n",
       " ('i', 28992651),\n",
       " ('o', 28818255),\n",
       " ('r', 26331592),\n",
       " ('s', 25200925),\n",
       " ('h', 19044643),\n",
       " ('l', 16223446),\n",
       " ('d', 16030336),\n",
       " ('c', 12135913),\n",
       " ('u', 10275908),\n",
       " ('m', 9441795),\n",
       " ('f', 8448546),\n",
       " ('g', 7719415),\n",
       " ('p', 7513193),\n",
       " ('w', 6528108),\n",
       " ('y', 6026960)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(data)\n",
    "c.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ = dict(c.items())\n",
    "occ = dict(sorted(occ.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 96 artists>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(occ.keys(), occ.values())\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~',\n",
       " 96,\n",
       " '\\n')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = ''.join(sorted(list(occ.keys())))\n",
    "chars, len(chars), chars[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~',\n",
       " 96,\n",
       " '\\n')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = ''.join(sorted(list(set(data))))\n",
    "chars, len(chars), chars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[66]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def enc(x, chars = chars):\n",
    "    idxs = []\n",
    "    for c in x:\n",
    "        idxs.append(chars.index(c))\n",
    "    return idxs\n",
    "\n",
    "def dec(x, chars = chars):\n",
    "    txt = ''\n",
    "    for i in x:\n",
    "        txt += chars[i]\n",
    "    return txt\n",
    "\n",
    "enc('a', chars)\n",
    "dec(enc('a', chars),chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1], ' ')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([46, 66, 73, 66, 79, 85, 73, 1, 58, 66, 77, 77, 66], 'Mahanth Yalla')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc(' ', chars), dec(enc(' ', chars),chars)\n",
    "enc('Mahanth Yalla', chars), dec(enc('Mahanth Yalla', chars),chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken \n",
    "\n",
    "tik = tiktoken.get_encoding('gpt2')\n",
    "tik.encode('a')\n",
    "tik.decode(tik.encode('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44, 19210, 400, 575, 30315]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Mahanth Yalla'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tik.encode('Mahanth Yalla')\n",
    "tik.decode(tik.encode('Mahanth Yalla'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tik.encode('&^$%\": >;.][>}{>.][][1239-]}]')\n",
    "# tik.decode(tik.encode('&^$%\": >;.][>}{>.][][1239-]}]'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing\n",
    "enc = enc\n",
    "dec = dec\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# # tiktoken\n",
    "# enc = tik.encode\n",
    "# dec = tik.decode\n",
    "# vocab_size = tik.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "development purpose, taking first 1M chars only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000000]), torch.int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([30,  1, 55, 66, 77, 76, 90, 83, 74, 66,  1, 36, 73, 83, 80, 79, 74, 68,\n",
       "        77, 70, 84,  1, 42, 42, 42])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(enc(data), dtype=torch.long)\n",
    "data.shape, data.dtype \n",
    "data[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([800000]), torch.Size([100000]), torch.Size([100000]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = int(0.8 * len(data))\n",
    "n2 = int(0.9 * len(data))\n",
    "Xtr = data[:n1]\n",
    "Xdev = data[n1:n2]\n",
    "Xte = data[n2:]\n",
    "Xtr.shape, Xdev.shape, Xte.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Batch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([30,  1, 55, 66, 77, 76, 90, 83]), '= Valkyr', tensor(66), 'i')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size  = 8\n",
    "Xtr[:block_size] , dec(Xtr[:block_size].numpy().astype(int)) , Xtr[block_size+1] , dec([Xtr[block_size].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> y\n",
      "y -> r\n",
      "yr -> i\n",
      "yri -> a\n",
      "yria ->  \n",
      "yria  -> o\n",
      "yria o -> f\n",
      "yria of ->  \n"
     ]
    }
   ],
   "source": [
    "start = 100\n",
    "for s in range(block_size):\n",
    "    context = Xtr[start:start + s]\n",
    "    target = Xtr[start + s]\n",
    "    print(f'{dec(context.numpy().astype(int))} -> {dec([target.item()])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8]), torch.Size([4, 8]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4 \n",
    "def get_batch(split):\n",
    "    if split == 'train':\n",
    "        X = Xtr\n",
    "    elif split == 'dev':\n",
    "        X = Xdev\n",
    "    else:\n",
    "        X = Xte\n",
    "    start = np.random.randint(0, len(X) - block_size - 1, (batch_size,))\n",
    "    X_batch = torch.stack([X[s:s + block_size] for s in start])\n",
    "    y_batch = torch.stack([X[s+1:s + block_size+1] for s in start])\n",
    "    return X_batch, y_batch\n",
    "\n",
    "X_batch, y_batch = get_batch('train')\n",
    "X_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[80, 79,  1, 80, 71,  1, 81, 83],\n",
       "         [79, 69,  1, 83, 70, 69, 74, 84],\n",
       "         [66,  1, 68, 80, 79, 84, 74, 69],\n",
       "         [77, 74, 85, 90,  1, 84, 85, 86]]),\n",
       " tensor([[79,  1, 80, 71,  1, 81, 83, 80],\n",
       "         [69,  1, 83, 70, 69, 74, 84, 85],\n",
       "         [ 1, 68, 80, 79, 84, 74, 69, 70],\n",
       "         [74, 85, 90,  1, 84, 85, 86, 69]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o -> n\n",
      "on ->  \n",
      "on  -> o\n",
      "on o -> f\n",
      "on of ->  \n",
      "on of  -> p\n",
      "on of p -> r\n",
      "n -> d\n",
      "nd ->  \n",
      "nd  -> r\n",
      "nd r -> e\n",
      "nd re -> d\n",
      "nd red -> i\n",
      "nd redi -> s\n",
      "a ->  \n",
      "a  -> c\n",
      "a c -> o\n",
      "a co -> n\n",
      "a con -> s\n",
      "a cons -> i\n",
      "a consi -> d\n",
      "l -> i\n",
      "li -> t\n",
      "lit -> y\n",
      "lity ->  \n",
      "lity  -> s\n",
      "lity s -> t\n",
      "lity st -> u\n"
     ]
    }
   ],
   "source": [
    "for i in range(batch_size):\n",
    "    for s in range(1,block_size):\n",
    "        print(f'{dec(X_batch[i].numpy().astype(int))[:s]} -> {dec(y_batch[i].numpy().astype(int))[s-1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# miniGPT-v1.0 - Bi-gram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expected loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.564348191467836"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(1/vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REUSING : model from [02_char_based_GPT_bigram.py](https://github.com/Mahanth-Maha/mahaMiniGPT/blob/main/02_char_based_GPT_bigram.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 96]), 4.853832721710205)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batch(split):\n",
    "    if split == 'train':\n",
    "        X = Xtr\n",
    "    elif split == 'dev':\n",
    "        X = Xdev\n",
    "    else:\n",
    "        X = Xte\n",
    "    start = np.random.randint(0, len(X) - block_size - 1, (batch_size,))\n",
    "    X_batch = torch.stack([X[s:s + block_size] for s in start])\n",
    "    y_batch = torch.stack([X[s+1:s + block_size+1] for s in start])\n",
    "    return X_batch, y_batch\n",
    "\n",
    "class BiGramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super(BiGramLanguageModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        # (batch_size, block_size, vocab_size)\n",
    "        logits = self.token_embedding_table(x)\n",
    "        if y is None:\n",
    "            return logits\n",
    "\n",
    "        # entropy expects : (N, C) input : (batch_size * block_size, vocab_size)\n",
    "        loss = F.cross_entropy(logits.view(-1, self.vocab_size), y.view(-1))\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, x, n_pred):\n",
    "        for _ in range(n_pred):\n",
    "            logits = self(x)[:, -1, :]\n",
    "            prob_dist = F.softmax(logits, -1)\n",
    "            x = torch.cat([x, torch.multinomial(prob_dist, 1)], -1)\n",
    "        return x\n",
    "    \n",
    "model = BiGramLanguageModel(vocab_size)\n",
    "# model.to('cpu')\n",
    "logits, loss = model(X_batch,y_batch)\n",
    "logits.shape, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 18])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['on of pr ROP+Ah[N_',\n",
       " 'nd redisjd* D@3Wl-',\n",
       " 'a considY/WRfhA({y',\n",
       " 'lity stu_BeaKxeHbV']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.generate(X_batch, 10) \n",
    "out.shape\n",
    "out_strs = [dec(x.numpy().astype(int)) for x in out]\n",
    "out_strs\n",
    "# literally random !!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.162155628204346"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_loss(model):\n",
    "    with torch.no_grad():\n",
    "        X_batch, y_batch = get_batch('dev')\n",
    "        logits, loss = model(X_batch, y_batch)\n",
    "        return loss.item()\n",
    "\n",
    "estimate_loss(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training using ~~SGD~~ AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-3\n",
    "optimiser = optim.AdamW(model.parameters(), lr=alpha) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "block_size = 16\n",
    "n_iters = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter : 0, Train Loss : 3.8952, Valid Loss : 3.9066\n",
      "Iter : 10000, Train Loss : 2.3962, Valid Loss : 2.4708\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m model(x, y)\n\u001b[0;32m      4\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m----> 5\u001b[0m \u001b[43moptimiser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m (n_iters \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\myalla\\anaconda3\\envs\\iisc\\lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    491\u001b[0m             )\n\u001b[1;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\myalla\\anaconda3\\envs\\iisc\\lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\myalla\\anaconda3\\envs\\iisc\\lib\\site-packages\\torch\\optim\\adam.py:247\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    235\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    237\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    238\u001b[0m         group,\n\u001b[0;32m    239\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m         state_steps,\n\u001b[0;32m    245\u001b[0m     )\n\u001b[1;32m--> 247\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupled_weight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\myalla\\anaconda3\\envs\\iisc\\lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\myalla\\anaconda3\\envs\\iisc\\lib\\site-packages\\torch\\optim\\adam.py:931\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    929\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 931\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\myalla\\anaconda3\\envs\\iisc\\lib\\site-packages\\torch\\optim\\adam.py:523\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[0;32m    521\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 523\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iter in range(n_iters):\n",
    "    x, y = get_batch('train')\n",
    "    logits, loss = model(x, y)\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    optimiser.zero_grad(set_to_none=True)\n",
    "    if iter % (n_iters // 10) == 0:\n",
    "        dev_loss = estimate_loss(model)\n",
    "        print(f'Iter : {iter}, Train Loss : {loss.item():.4f}, Valid Loss : {dev_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iisc",
   "language": "python",
   "name": "iisc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
